{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11220,"sourceType":"modelInstanceVersion","modelInstanceId":8749,"modelId":3301},{"sourceId":11221,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":8655,"modelId":3301},{"sourceId":11225,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":5384,"modelId":3301},{"sourceId":11359,"sourceType":"modelInstanceVersion","modelInstanceId":8749,"modelId":3301},{"sourceId":11360,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":8655,"modelId":3301},{"sourceId":11361,"sourceType":"modelInstanceVersion","modelInstanceId":5384,"modelId":3301}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Choose variant and machine type\nVARIANT = '7b-it-quant' #@param ['2b', '2b-it', '9b', '9b-it', '27b', '27b-it']\nMACHINE_TYPE = 'cuda' #@param ['cuda', 'cpu']\n\nCONFIG = VARIANT\nif CONFIG == '7b-it-quant':\n    CONFIG = '7b'","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:16:48.945488Z","iopub.execute_input":"2024-09-06T06:16:48.945917Z","iopub.status.idle":"2024-09-06T06:16:48.951063Z","shell.execute_reply.started":"2024-09-06T06:16:48.945877Z","shell.execute_reply":"2024-09-06T06:16:48.950069Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:16:48.953049Z","iopub.execute_input":"2024-09-06T06:16:48.953716Z","iopub.status.idle":"2024-09-06T06:16:52.150777Z","shell.execute_reply.started":"2024-09-06T06:16:48.953672Z","shell.execute_reply":"2024-09-06T06:16:52.149961Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"weights_dir = \"/kaggle/input/gemma/pytorch/7b-it-quant/2\"","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:16:52.151885Z","iopub.execute_input":"2024-09-06T06:16:52.152278Z","iopub.status.idle":"2024-09-06T06:16:52.156281Z","shell.execute_reply.started":"2024-09-06T06:16:52.152244Z","shell.execute_reply":"2024-09-06T06:16:52.155380Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\n# Ensure that the tokenizer is present\ntokenizer_path = os.path.join(weights_dir, 'tokenizer.model')\nassert os.path.isfile(tokenizer_path), 'Tokenizer not found!'\n\n# Ensure that the checkpoint is present\nckpt_path = os.path.join(weights_dir, f'gemma-7b-it-quant.ckpt')\nassert os.path.isfile(ckpt_path), 'PyTorch checkpoint not found!'","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:16:52.157443Z","iopub.execute_input":"2024-09-06T06:16:52.157712Z","iopub.status.idle":"2024-09-06T06:16:52.177425Z","shell.execute_reply.started":"2024-09-06T06:16:52.157683Z","shell.execute_reply":"2024-09-06T06:16:52.176723Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# NOTE: The \"installation\" is just cloning the repo.\n!git clone https://github.com/google/gemma_pytorch.git","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:16:52.179286Z","iopub.execute_input":"2024-09-06T06:16:52.179599Z","iopub.status.idle":"2024-09-06T06:16:53.989129Z","shell.execute_reply.started":"2024-09-06T06:16:52.179563Z","shell.execute_reply":"2024-09-06T06:16:53.987989Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Cloning into 'gemma_pytorch'...\nremote: Enumerating objects: 239, done.\u001b[K\nremote: Counting objects: 100% (123/123), done.\u001b[K\nremote: Compressing objects: 100% (68/68), done.\u001b[K\nremote: Total 239 (delta 86), reused 58 (delta 55), pack-reused 116 (from 1)\u001b[K\nReceiving objects: 100% (239/239), 2.18 MiB | 18.42 MiB/s, done.\nResolving deltas: 100% (135/135), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\n\nsys.path.append('gemma_pytorch')","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:16:53.990683Z","iopub.execute_input":"2024-09-06T06:16:53.991028Z","iopub.status.idle":"2024-09-06T06:16:53.995541Z","shell.execute_reply.started":"2024-09-06T06:16:53.990990Z","shell.execute_reply":"2024-09-06T06:16:53.994663Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from gemma.config import GemmaConfig, get_model_config\nfrom gemma.model import GemmaForCausalLM\nfrom gemma.tokenizer import Tokenizer\nimport contextlib\nimport os\nimport torch","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:16:53.996735Z","iopub.execute_input":"2024-09-06T06:16:53.997014Z","iopub.status.idle":"2024-09-06T06:16:54.033589Z","shell.execute_reply.started":"2024-09-06T06:16:53.996984Z","shell.execute_reply":"2024-09-06T06:16:54.032878Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Set up model config.\nmodel_config = get_model_config(CONFIG)\nmodel_config.tokenizer = tokenizer_path\nmodel_config.quant = 'quant' in VARIANT\ntorch.cuda.empty_cache()\n\n# Instantiate the model and load the weights.\ntorch.set_default_dtype(model_config.get_dtype())\ndevice = torch.device(MACHINE_TYPE)\nmodel = GemmaForCausalLM(model_config)\nmodel.load_weights(ckpt_path)\nmodel = model.to(device).eval()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:16:54.034608Z","iopub.execute_input":"2024-09-06T06:16:54.034891Z","iopub.status.idle":"2024-09-06T06:18:00.610076Z","shell.execute_reply.started":"2024-09-06T06:16:54.034860Z","shell.execute_reply":"2024-09-06T06:18:00.608926Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import time\n\n# Đo thời gian cho việc sinh mẫu\nstart_time = time.time()\n\nsentence = \"\"\"\n    Trận Điện Biên Phủ, còn gọi là Chiến dịch Điện Biên Phủ là trận đánh lớn nhất trong Chiến tranh Đông Dương lần thứ nhất diễn ra tại lòng chảo Mường Thanh, châu Điện Biên, tỉnh Lai Châu (nay thuộc thành phố Điện Biên Phủ, tỉnh Điện Biên) giữa Quân đội Nhân dân Việt Nam và Quân đội Liên hiệp Pháp (gồm Lực lượng Viễn chinh Pháp, Binh đoàn Lê dương Pháp, quân phụ lực bản xứ và Quân đội Quốc gia Việt Nam). Đây là chiến thắng quân sự lớn nhất trong cuộc Chiến tranh Đông Dương (1945 – 1954) của Việt Nam. Với thắng lợi quyết định này, lực lượng Quân đội Nhân dân Việt Nam do Đại tướng Võ Nguyên Giáp chỉ huy đã buộc quân Pháp và quân Quốc Gia Việt Nam tại Điện Biên Phủ phải đầu hàng vào ngày 7 tháng 5 năm 1954, sau suốt 2 tháng cầm cự. Giữa trận này, quân Pháp đã gia tăng lên đến 16.200 người nhưng vẫn không thể cầm cự được trước các đợt tấn công như vũ bão của Quân đội Nhân dân Việt Nam. Thực dân Pháp đã không thể bình định Việt Nam bất chấp nhiều năm chiến đấu và với sự hỗ trợ và can dự ngày càng sâu của Hoa Kỳ. Pháp đã không còn bất kì khả năng nào để tiếp tục chiến đấu tại Việt Nam sau thảm bại này. Trên phương diện quốc tế, chiến dịch này có một ý nghĩa rất lớn và đã đi vào lịch sử nhân loại, bởi đây là lần đầu tiên quân đội của một nước từng là thuộc địa ở châu Á đánh bại đội quân hiện đại và tối tân của một cường quốc châu Âu, được hỗ trợ bởi đồng minh là Hoa Kỳ trong một chiến dịch quân sự lớn. Được xem là một thảm họa bất ngờ đối với thực dân Pháp và cũng là một đòn giáng mạnh với thế giới phương Tây, đã đánh bại ý chí duy trì thuộc địa Đông Dương của Pháp và buộc nước này phải hòa đàm và rút quân ra khỏi Đông Dương. Với niềm tin được cổ vũ mạnh mẽ bởi chiến thắng này, các thuộc địa của Pháp ở châu Phi cũng đồng loạt nổi dậy đòi độc lập. Chỉ riêng trong năm 1960, 17 nước châu Phi đã giành được độc lập và đến năm 1967, Pháp đã buộc phải trao trả độc lập cho hầu hết các nước từng là thuộc địa của họ.\n\"\"\"\nword_count = len(sentence.split(' '))\nlimit = 200\n\nlow_range = int(word_count * 0.5)\nlimit = low_range if low_range > limit else limit\n\nprompt = f\"\"\"<start_of_turn> \n            Hãy tóm tắt đoạn văn sau\n              {sentence} \n            Lưu ý:\n                - Văn bản đã tóm tắt phải là đơn văn bản.\n                - Văn bản đã tóm tắt phải được viết bằng ngôn ngữ tiếng Việt.\n                - Văn bản đã tóm tắt phải được tổ chức theo định dạng Markdown, trong đó phải có\n                  cụm '## Tóm tắt: ' ở đầu văn bản, văn bản đã tóm tắt phải được đặt sau cụm này.\n                - Văn bản đã tóm tắt phải được chuẩn hoá, loại bỏ các khoảng trống dư thừa.\n                - Chỉ tóm tắt ý, không thực hiện bất kỳ tác vụ nào khác.\n                - Độ dài tối đa {limit} từ.\n            <end_of_turn>\n            \"\"\"\n\n# Generate sample\nresults = model.generate(\n    prompt,\n    device=device,\n    output_len=limit,\n)\nprint(results)\ngeneration_time = time.time() - start_time\nprint(generation_time)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:20:26.196266Z","iopub.execute_input":"2024-09-06T06:20:26.196585Z","iopub.status.idle":"2024-09-06T06:21:57.886612Z","shell.execute_reply.started":"2024-09-06T06:20:26.196546Z","shell.execute_reply":"2024-09-06T06:21:57.885573Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"## Tóm tắt:\n\nTrận Điện Biên Phủ là chiến thắng quân sự lớn nhất trong cuộc chiến tranh Đông Dương của Việt Nam. Với thắng lợi quyết định này, lực lượng Quân đội nhân dân Việt Nam đã buộc quân Pháp và quân Quốc Gia Việt Nam tại Điện Biên Phủ phải đầu hàng vào ngày 7 tháng 5 năm 1954. chiến dịch này có một ý nghĩa rất lớn và đã đi vào lịch sử nhân loại bởi đây là lần đầu tiên quân đội của một nước từng là thuộc địa ở châu Á đánh bại đội quân hiện đại và tối tân của một cường quốc châu Âu, được hỗ trợ bởi đồng minh là Hoa Kỳ trong một chiến dịch quân sự lớn\n91.68055653572083\n","output_type":"stream"}]},{"cell_type":"code","source":"# Generate with one request in chat mode\n\n# Chat templates\nUSER_CHAT_TEMPLATE = \"<start_of_turn>user\\n{prompt}<end_of_turn><eos>\\n\"\nMODEL_CHAT_TEMPLATE = \"<start_of_turn>model\\n{prompt}<end_of_turn><eos>\\n\"\n\n# Sample formatted prompt\nprompt = (\n    USER_CHAT_TEMPLATE.format(\n        prompt='What is a good place for travel in the US?'\n    )\n    + MODEL_CHAT_TEMPLATE.format(prompt='California.')\n    + USER_CHAT_TEMPLATE.format(prompt='What can I do in California?')\n    + '<start_of_turn>model\\n'\n)\nprint('Chat prompt:\\n', prompt)\n\nresults = model.generate(\n    USER_CHAT_TEMPLATE.format(prompt=prompt),\n    device=device,\n    output_len=128,\n)\nprint(results)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T06:21:57.888023Z","iopub.execute_input":"2024-09-06T06:21:57.888831Z","iopub.status.idle":"2024-09-06T06:22:51.077509Z","shell.execute_reply.started":"2024-09-06T06:21:57.888783Z","shell.execute_reply":"2024-09-06T06:22:51.076580Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Chat prompt:\n <start_of_turn>user\nWhat is a good place for travel in the US?<end_of_turn><eos>\n<start_of_turn>model\nCalifornia.<end_of_turn><eos>\n<start_of_turn>user\nWhat can I do in California?<end_of_turn><eos>\n<start_of_turn>model\n\nThere's a lot to see and do in California, depending on your interests and preferences:\n\n**Classic destinations:**\n- **San Francisco:** Golden Gate Bridge, Alcatraz Island, Chinatown, Golden Gate Park\n- **Los Angeles:** Hollywood Walk of Fame, Griffith Observatory, Santa Monica Pier, Rodeo Drive\n- **San Diego:** Balboa Park, La Jolla Cove, Altoshahar National Monument\n- **Lake Tahoe:** Beautiful mountain scenery, hiking trails, boating and water sports\n\n**Other popular destinations:**\n- Monterey and Carmel-by-the-Sea: Charming coastal towns\n- Yosemite National Park: Majestic granite\n","output_type":"stream"}]}]}